# ============================================================
# ğŸ—‚ï¸ HIERARCHICAL DATASET PREPROCESSING - BEGINNER FRIENDLY
# ============================================================

# ğŸ“– WHAT IS HIERARCHICAL DATA?
# This is when your images are organized in folders, where each folder name is a species/class name.
# Example structure:
# your_data/
# â”œâ”€â”€ species_A/
# â”‚   â”œâ”€â”€ image1.jpg
# â”‚   â”œâ”€â”€ image2.jpg
# â”œâ”€â”€ species_B/
# â”‚   â”œâ”€â”€ image3.jpg
# â”‚   â””â”€â”€ image4.jpg

# ğŸ“‚ INPUT DATA CONFIGURATION
input_source:
  type: "hierarchical"          # Tell the system this is folder-organized data
  data_path: "DATA/sample_hierarchical"  # ğŸ—‚ï¸ Path to your main data folder
                                         # Change this to point to YOUR data folder
  subdirs: []                   # ğŸ“ Empty = class folders are directly under data_path
                                # If your data has extra folder levels, specify them here
                                # Example: ["train"] if you have DATA/your_data/train/species_folders/

# ğŸ”§ PREPROCESSING SETTINGS
preprocessing:
  
  # ğŸ—ï¸ SCALEBAR REMOVAL (removes scale bars from microscopy images)
  scalebar_removal:
    enabled: true               # ğŸ” Whether to detect and remove scale bars from images
                                # true = remove scale bars (RECOMMENDED for microscopy images)
                                # false = leave images unchanged
                                
    model_path: "models/model_weights/scale_bar_remover/best.pt"  # ğŸ¤– Pre-trained scale bar detection model
                                                                  # Don't change this path - it's the trained model
                                                                  
    confidence: 0.4             # ğŸ¯ How confident the model needs to be to detect a scale bar (0.0-1.0)
                                # 0.4 = good balance, detects most scale bars without false positives
                                # Lower = detects more scale bars but may make mistakes
                                # Higher = more careful but might miss some scale bars
                                
    img_size: 416               # ğŸ“ Image size for scale bar detection model
                                # Keep this at 416 - it's optimized for the detection model
  
  # ğŸ¨ COLOR CONVERSION
  grayscale_conversion:
    enabled: true               # ğŸŒˆ Convert grayscale images to RGB format
                                # true = ensure all images have color channels (RECOMMENDED)
                                # false = keep original format (only if all images are already RGB)
    mode: "RGB"                 # Color mode - keep as "RGB"
  
  # ğŸ§¹ IMAGE FILTERING (removes bad/insufficient data)
  image_filtering:
    min_images_per_class: 10    # ğŸ“Š Remove classes with fewer than this many images
                                # Classes with too few images can't be learned properly
                                # 10 is minimum, 50+ is better for good results
                                
    max_images_per_class: null  # ğŸ“ Maximum images per class (null = no limit)
                                # Set a number (e.g., 1000) if some classes have too many images
                                # null = keep all images
                                
    skip_corrupted_images: true # ğŸš« Skip images that can't be opened
                                # true = ignore broken image files (RECOMMENDED)
  
  # ğŸ“Š DATA SPLITTING (divide data into training/validation/test sets)
  data_splitting:
    train_ratio: 0.7            # ğŸ‹ï¸ Fraction of data for training (0.7 = 70%)
                                # This is where the model learns patterns
                                
    val_ratio: 0.2              # ğŸ“ Fraction for validation (0.2 = 20%)
                                # Used to monitor training progress and tune settings
                                
    test_ratio: 0.1             # ğŸ§ª Fraction for final testing (0.1 = 10%)
                                # Used to evaluate final model performance
                                # train_ratio + val_ratio + test_ratio must equal 1.0
                                
    stratified: true            # âš–ï¸ Keep class proportions balanced across splits
                                # true = each split has similar class distribution (RECOMMENDED)
                                
    random_seed: 42             # ğŸ² Random seed for reproducible splits
                                # Same seed = same splits every time you run preprocessing
  
  # ğŸ”„ DATA AUGMENTATION (creates more training examples)
  augmentation:
    enabled: true               # ğŸ¨ Create additional training images through transformations
                                # true = more training data, better model performance (RECOMMENDED)
                                # false = use only original images
                                
    target_images_per_class: 30 # ğŸ¯ Target number of images per class after augmentation
                                # Smaller datasets: try 50-200
                                # Larger datasets: try 500-2000
                                # Adjust based on your computational resources
                                
    max_copies_per_image: 3     # ğŸ“¸ Maximum augmented versions per original image
                                # Higher = more variety but also more processing time
                                # 3-5 is usually a good range

    # ğŸ­ AUGMENTATION TECHNIQUES (how to modify images)
    # Each number is the probability (0.0-1.0) of applying that transformation
    techniques:
      horizontal_flip: 0.5      # ğŸ”„ Flip image left-right (50% chance)
                                # Good for most natural images
                                
      vertical_flip: 0.2        # â†•ï¸ Flip image top-bottom (20% chance)
                                # Lower probability - not all images make sense flipped vertically
                                
      rotate_90: 0.3            # ğŸ”„ Rotate by 90 degrees (30% chance)
                                # Good for microscopy images that can be oriented any way
                                
      brightness_contrast: 0.4  # â˜€ï¸ Adjust brightness and contrast (40% chance)
                                # Helps model handle different lighting conditions
                                
      hue_saturation: 0.3       # ğŸŒˆ Adjust color properties (30% chance)
                                # Helps with color variations in images
      
# ğŸ“ OUTPUT CONFIGURATION (where to save processed data)
output:
  base_path: "DATA/sample_hierarchical"                    # ğŸ“‚ Keep same as input data_path
                                                           # Base folder for organizing outputs
                                                           
  processed_path: "DATA/sample_hierarchical_processed"     # ğŸ”§ Intermediate processing folder
                                                           # Images after scalebar removal and filtering
                                                           # You usually don't need to look in here
                                                           
  final_dataset_path: "DATA/sample_hierarchical_final_dataset"  # ğŸ¯ FINAL OUTPUT FOLDER
                                                                # This is what you'll use for training!
                                                                # Contains train/, val/, test/ folders
                                                                
  create_dataset_yaml: true                                # ğŸ“„ Create dataset.yaml file for training
                                                           # true = creates config file needed for training (REQUIRED)
                                                           # false = skip yaml creation (only if you already have one)

# ğŸ“Š LOGGING CONFIGURATION (track what happens during preprocessing)
logging:
  wandb_enabled: false          # ğŸŒ Upload preprocessing logs to Weights & Biases
                                # false = keep logs local only (RECOMMENDED for preprocessing)
                                # true = upload statistics and charts online
  
  # These features are not yet implemented                                     
  log_class_distribution: true  # ğŸ“Š Show how many images per class
                                # true = see statistics about your data balance
  log_sample_images: false      # ğŸ–¼ï¸ Save example processed images
                                # false = faster processing (RECOMMENDED)
                                # true = save examples to see what preprocessing did                      
  log_processing_times: true    # â±ï¸ Track how long each step takes
                                # true = see performance statistics

# ğŸ’¡ QUICK START GUIDE:
# 1. Change data_path to point to YOUR image folders
# 2. Adjust target_images_per_class based on your dataset size:
#    - Small dataset (< 1000 images): try 100-300
#    - Medium dataset (1000-10000 images): try 500-1000  
#    - Large dataset (> 10000 images): try 1000-3000
# 3. Run: python3 run_preprocessing.py --config configs/preprocessing/PreprocessWithHierarchical.yaml
# 4. Use the final_dataset_path folder for training!

# ğŸš¨ COMMON ISSUES:
# - "No classes found": Check that data_path points to folder containing species folders
# - "Not enough images": Reduce min_images_per_class or get more data
# - "Out of memory": Reduce target_images_per_class or max_copies_per_image
