# ============================================================
# 🐚 EcoTaxa DATASET PREPROCESSING - BEGINNER FRIENDLY
# ============================================================

# 📖 WHAT IS EcoTaxa?
# EcoTaxa is a web application used by marine biologists for plankton image classification.
# When you export data from EcoTaxa, you get:
# 1. A folder with all the plankton images
# 2. A TSV (tab-separated) file with detailed metadata about each image
#
# Example EcoTaxa export structure:
# YourEcoTaxaDataset/
# ├── images/
# │   ├── img_12345.jpg
# │   ├── img_12346.jpg
# │   └── ...
# └── ecotaxa_export_TSV_xxxxx.tsv  (contains detailed info about each image)

# 📂 INPUT DATA CONFIGURATION
input_source:
  type: "ecotaxa"                           # Tell system this is EcoTaxa format data
  
  data_path: "DATA/YourEcoTaxaDataset"      # 📁 Main folder containing your EcoTaxa export
                                           # Should contain both images folder and TSV file
                                           
  metadata_file: "ecotaxa_export__TSV_17354_20250616_1138.tsv"  # 📄 TSV file from EcoTaxa export
                                                                # ⚠️ Change this to YOUR actual TSV filename!
                                                                # The filename usually includes export ID and date
                                                                
  separator: "\t"                         # 📊 EcoTaxa uses tab-separated values
                                          # Always keep this as "\t" for EcoTaxa data
                                          # We also expect the TSV file with 2 header lines (one for columns, one for database specific fields)

# 🔧 PREPROCESSING SETTINGS
preprocessing:
  
  # 🏗️ SCALEBAR REMOVAL (removes scale bars from microscopy images)
  scalebar_removal:
    enabled: true               # 🔍 Whether to detect and remove scale bars from images
                                # true = remove scale bars (RECOMMENDED for microscopy images)
                                # false = leave images unchanged
                                
    model_path: "models/model_weights/scale_bar_remover/best.pt"  # 🤖 Pre-trained scale bar detection model
                                                                  # Don't change this path - it's the trained model
                                                                  
    confidence: 0.4             # 🎯 How confident the model needs to be to detect a scale bar (0.0-1.0)
                                # 0.4 = good balance, detects most scale bars without false positives
                                # Lower = detects more scale bars but may make mistakes
                                # Higher = more careful but might miss some scale bars
                                
    img_size: 416               # 📐 Image size for scale bar detection model
                                # Keep this at 416 - it's optimized for the detection model
  
  # 🎨 COLOR CONVERSION
  grayscale_conversion:
    enabled: true               # 🌈 Convert grayscale images to RGB format
                                # true = ensure all images have color channels (RECOMMENDED)
                                # false = keep original format (only if all images are already RGB)
    mode: "RGB"                 # Color mode - keep as "RGB"
  
  # 🧹 IMAGE FILTERING (removes bad/insufficient data)
  image_filtering:
    min_images_per_class: 10    # 📊 Remove classes with fewer than this many images
                                # Classes with too few images can't be learned properly
                                # 10 is minimum, 50+ is better for good results
                                
    max_images_per_class: null  # 📏 Maximum images per class (null = no limit)
                                # Set a number (e.g., 1000) if some classes have too many images
                                # null = keep all images
                                
    skip_corrupted_images: true # 🚫 Skip images that can't be opened
                                # true = ignore broken image files (RECOMMENDED)
  
  # 📊 DATA SPLITTING (divide data into training/validation/test sets)
  data_splitting:
    train_ratio: 0.7            # 🏋️ Fraction of data for training (0.7 = 70%)
                                # This is where the model learns patterns
                                
    val_ratio: 0.2              # 📏 Fraction for validation (0.2 = 20%)
                                # Used to monitor training progress and tune settings
                                
    test_ratio: 0.1             # 🧪 Fraction for final testing (0.1 = 10%)
                                # Used to evaluate final model performance
                                # train_ratio + val_ratio + test_ratio must equal 1.0
                                
    stratified: true            # ⚖️ Keep class proportions balanced across splits
                                # true = each split has similar class distribution (RECOMMENDED)
                                
    random_seed: 42             # 🎲 Random seed for reproducible splits
                                # Same seed = same splits every time you run preprocessing
  
  # 🔄 DATA AUGMENTATION (creates more training examples)
  augmentation:
    enabled: true               # 🎨 Create additional training images through transformations
                                # true = more training data, better model performance (RECOMMENDED)
                                # false = use only original images
                                
    target_images_per_class: 30 # 🎯 Target number of images per class after augmentation
                                # Smaller datasets: try 50-200
                                # Larger datasets: try 500-2000
                                # Adjust based on your computational resources
                                
    max_copies_per_image: 3     # 📸 Maximum augmented versions per original image
                                # Higher = more variety but also more processing time
                                # 3-5 is usually a good range

    # 🎭 AUGMENTATION TECHNIQUES (how to modify images)
    # Each number is the probability (0.0-1.0) of applying that transformation
    techniques:
      horizontal_flip: 0.5      # 🔄 Flip image left-right (50% chance)
                                # Good for most natural images
                                
      vertical_flip: 0.2        # ↕️ Flip image top-bottom (20% chance)
                                # Lower probability - not all images make sense flipped vertically
                                
      rotate_90: 0.3            # 🔄 Rotate by 90 degrees (30% chance)
                                # Good for microscopy images that can be oriented any way
                                
      brightness_contrast: 0.4  # ☀️ Adjust brightness and contrast (40% chance)
                                # Helps model handle different lighting conditions
                                
      hue_saturation: 0.3       # 🌈 Adjust color properties (30% chance)
                                # Helps with color variations in images

# 📁 OUTPUT CONFIGURATION (where to save processed data)
output:
  # Base path for output files
  base_path: "DATA/YourEcoTaxaDataset"
  # Processed path where files with no scale bars will be saved
  processed_path: "DATA/YourEcoTaxaDataset_processed"
  # Final dataset path where the final dataset will be saved
  final_dataset_path: "DATA/YourEcoTaxaDataset_final_dataset"
  # Unless you already have a dataset YAML file correctly formatted, please always set this to true since its needed for training
  create_dataset_yaml: true
  
# 📊 LOGGING CONFIGURATION (track what happens during preprocessing)
logging:
  wandb_enabled: false          # 🌐 Upload preprocessing logs to Weights & Biases
                                # false = keep logs local only (RECOMMENDED for preprocessing)
                                # true = upload statistics and charts online
  
  # These features are not yet implemented                                     
  log_class_distribution: true  # 📊 Show how many images per class
                                # true = see statistics about your data balance
  log_sample_images: false      # 🖼️ Save example processed images
                                # false = faster processing (RECOMMENDED)
                                # true = save examples to see what preprocessing did                      
  log_processing_times: true    # ⏱️ Track how long each step takes
                                # true = see performance statistics