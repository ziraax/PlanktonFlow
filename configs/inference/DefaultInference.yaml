# ============================================================
# ðŸ”® MODEL INFERENCE CONFIGURATION - BEGINNER FRIENDLY
# ============================================================

# ðŸ“– WHAT IS INFERENCE?
# Inference means using your trained model to make predictions on new, unseen images.
# After training a model, you use this config to classify new images and get species predictions.


# ðŸ¤– MODEL CONFIGURATION (which trained model to use)
model:
  name: "densenet"              # Type of model architecture
  variant: "161"                # Model size/variant
  weights_path: "model_weights/densenet/161/DenseNet_Default_Config_Run_CARO_20250818_144738/best.pt"
  num_classes: 5                # Number of classes the model was trained on

# ðŸ“„ DATASET YAML (for class names)
dataset_yaml: "DATA/sample_hierarchical_final_dataset/dataset.yaml"  # <-- Path to the YAML file containing class names
  # This file is generated automatically during preprocessing.
  # It MUST match the dataset used for training this model.
  # The class names will be read from the 'names' field in this YAML.

# ðŸ” INFERENCE SETTINGS (how to run predictions)
inference:
  image_dir: "DATA/ecotaxa_infer_set"  # ðŸ“‚ Folder containing images to classify
                                       # Point this to your new images (not training data!)
                                       # All .jpg, .jpeg, .png files in this folder will be processed
                                       
  batch_size: 32                # ðŸ”¢ Number of images processed at once
                                # Larger = faster but uses more GPU memory
                                # If you get "out of memory" errors, try 16, 8, or 4
                                # If you have lots of GPU memory, try 64 or 128
                                
  top_k: 5                      # ðŸŽ¯ Number of top predictions to return per image
                                # 5 = show top 5 most likely species with confidence scores
                                # Useful to see alternative predictions, not just the best one
                                
  device: "cuda"                # ðŸ’» Where to run inference
                                # "cuda" = use GPU (MUCH faster, recommended)
                                # "cpu" = use CPU (slower but works without GPU)
                                
  save_csv: true                # ðŸ’¾ Save results to a CSV file
                                # true = create spreadsheet with all predictions (RECOMMENDED)
                                # false = only show results in terminal
                                
  output_path: "outputs/results_caro.csv"  # ðŸ“„ Where to save the CSV results file
                                           # Change "results_caro.csv" to your preferred filename
                                           # Will contain: image_path, top predictions, confidence scores

# ðŸ”§ OPTIONAL PREPROCESSING (clean images before prediction)
preprocessing:
  scalebar_removal: false        # ðŸ” Remove scale bars from images before classification
                                # true = detect and remove scale bars (RECOMMENDED for microscopy)
                                # false = use images as-is
                                # Should match what you used during training data preprocessing
  
# ðŸ“Š EXPERIMENT TRACKING (Weights & Biases)
wandb:
  log_results: false             # ðŸ“ˆ Upload results to Weights & Biases
                                # true = see results online with charts and images
                                # false = keep results local only
                                
  tags: ["inference", "production", "classification"]  # ðŸ·ï¸ Organize your inference runs
  
  notes: "Inference run on new dataset using trained DenseNet model"  # ðŸ“ Description

# ðŸ’¡ BEGINNER TIPS:
# 1. Make sure weights_path points to a model trained on similar data
# 2. Ensure num_classes matches your training (check training logs or dataset.yaml)
# 3. Start with a small batch of test images first
# 4. Check the CSV output to understand prediction confidence scores
# 5. Low confidence scores (< 0.5) might indicate the model is uncertain

# ðŸ“Š UNDERSTANDING RESULTS:
# The CSV output will show:
# - image_path: name of each image
# - top1_label, top1_score: most likely species and confidence (0-1)
# - top2_label, top2_score: second most likely species and confidence
# - etc. for top_k predictions
# 
# Confidence scores closer to 1.0 = model is very confident
# Scores closer to 0.0 = model is uncertain (might be unusual image)
